{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "ILGti4l-iIJw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY-WJuyMvBxb",
        "outputId": "7a9215f4-9c59-4b17-9040-0d2dcd757825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=gutenberg.raw('shakespeare-hamlet.txt')\n",
        "with open('hamlet.txt','w') as file:\n",
        "  file.write(data)"
      ],
      "metadata": {
        "id": "8nMKHPwhxxo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "PtsinElSykjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "hls5gtVWykH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset"
      ],
      "metadata": {
        "id": "YXkAJmFJzYxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('hamlet.txt','r') as file:\n",
        "  text=file.read().lower()"
      ],
      "metadata": {
        "id": "5dSQl93JzXor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the Text"
      ],
      "metadata": {
        "id": "96-e8f6V0BK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words=len(tokenizer.word_index)+1\n",
        "total_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIQNByFI0Hb6",
        "outputId": "51b8e396-8258-453a-f3e7-b878ab9049a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4818"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the input sequences"
      ],
      "metadata": {
        "id": "ILa07mTx0FSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences=[]\n",
        "for line in text.split('\\n'):\n",
        "  token_list=tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1,len(token_list)):\n",
        "    n_gram_sequence=token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "IRP1kLEB1HcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pad Sequences"
      ],
      "metadata": {
        "id": "wcPOKIjq4aXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len=max([len(x) for x in input_sequences])\n",
        "max_sequence_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT-9WlOe4L-A",
        "outputId": "136f263f-8d6e-478b-b2ae-ccbe9e1a5739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences=np.array(pad_sequences(input_sequences,maxlen=max_sequence_len,padding='pre'))\n",
        "input_sequences.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jph8GnTz44HO",
        "outputId": "a7aedb0a-7977-457f-a297-435fc13aaf49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25732, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating Predictors and Label"
      ],
      "metadata": {
        "id": "AdZUQduc6DZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "x,y=input_sequences[:,:-1],input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "EXrPZk6C6I_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=tf.keras.utils.to_categorical(y,num_classes=total_words)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdK9Pu0g61ss",
        "outputId": "bb866295-6e44-42c9-ea9b-057ee2ac7e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into training and testing sets"
      ],
      "metadata": {
        "id": "ngwXLx9H4Hjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
      ],
      "metadata": {
        "id": "0Ban6oYS7aEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\n",
        "\n",
        "#Defining the model\n",
        "model=Sequential()\n",
        "model.add(Embedding(total_words,100,input_length=max_sequence_len-1))\n",
        "model.add(LSTM(150,return_sequences=True))\n",
        "model.add(Dropout (0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words,activation='softmax'))\n",
        "\n",
        "model.build(input_shape=(None, max_sequence_len - 1))\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "Jn5UzkVx8CFr",
        "outputId": "a4a25f1d-8d8b-4ea8-adba-d90efcefa260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │         \u001b[38;5;34m481,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │         \u001b[38;5;34m150,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │         \u001b[38;5;34m100,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4818\u001b[0m)                │         \u001b[38;5;34m486,618\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">481,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4818</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">486,618</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,219,418\u001b[0m (4.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,219,418</span> (4.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,219,418\u001b[0m (4.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,219,418</span> (4.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "histroy=model.fit(x_train,y_train,epochs=100,validation_data=(x_test,y_test),verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "v3eygRAZ_0Ew",
        "outputId": "429e130d-b8ea-4745-fa83-55d4ed612985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 73ms/step - accuracy: 0.0319 - loss: 7.1545 - val_accuracy: 0.0344 - val_loss: 6.7363\n",
            "Epoch 2/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.0357 - loss: 6.4725 - val_accuracy: 0.0439 - val_loss: 6.8222\n",
            "Epoch 3/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 71ms/step - accuracy: 0.0435 - loss: 6.2835 - val_accuracy: 0.0482 - val_loss: 6.8716\n",
            "Epoch 4/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.0548 - loss: 6.1485 - val_accuracy: 0.0505 - val_loss: 6.8848\n",
            "Epoch 5/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 68ms/step - accuracy: 0.0546 - loss: 6.0000 - val_accuracy: 0.0544 - val_loss: 6.9056\n",
            "Epoch 6/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 68ms/step - accuracy: 0.0643 - loss: 5.8668 - val_accuracy: 0.0600 - val_loss: 6.9512\n",
            "Epoch 7/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 67ms/step - accuracy: 0.0764 - loss: 5.7011 - val_accuracy: 0.0618 - val_loss: 7.0331\n",
            "Epoch 8/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 68ms/step - accuracy: 0.0861 - loss: 5.5833 - val_accuracy: 0.0668 - val_loss: 7.0894\n",
            "Epoch 9/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 67ms/step - accuracy: 0.0907 - loss: 5.4701 - val_accuracy: 0.0659 - val_loss: 7.1779\n",
            "Epoch 10/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 68ms/step - accuracy: 0.0962 - loss: 5.3338 - val_accuracy: 0.0659 - val_loss: 7.2677\n",
            "Epoch 11/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 68ms/step - accuracy: 0.0967 - loss: 5.2450 - val_accuracy: 0.0719 - val_loss: 7.3992\n",
            "Epoch 12/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 68ms/step - accuracy: 0.1074 - loss: 5.1008 - val_accuracy: 0.0653 - val_loss: 7.4840\n",
            "Epoch 13/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 66ms/step - accuracy: 0.1157 - loss: 4.9813 - val_accuracy: 0.0686 - val_loss: 7.5764\n",
            "Epoch 14/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 68ms/step - accuracy: 0.1209 - loss: 4.8825 - val_accuracy: 0.0670 - val_loss: 7.7110\n",
            "Epoch 15/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 68ms/step - accuracy: 0.1206 - loss: 4.7672 - val_accuracy: 0.0692 - val_loss: 7.7902\n",
            "Epoch 16/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 67ms/step - accuracy: 0.1302 - loss: 4.6334 - val_accuracy: 0.0663 - val_loss: 7.9436\n",
            "Epoch 17/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 67ms/step - accuracy: 0.1397 - loss: 4.4995 - val_accuracy: 0.0651 - val_loss: 8.0574\n",
            "Epoch 18/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 67ms/step - accuracy: 0.1409 - loss: 4.4271 - val_accuracy: 0.0663 - val_loss: 8.2246\n",
            "Epoch 19/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 68ms/step - accuracy: 0.1485 - loss: 4.3394 - val_accuracy: 0.0616 - val_loss: 8.3440\n",
            "Epoch 20/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.1619 - loss: 4.2203 - val_accuracy: 0.0655 - val_loss: 8.4480\n",
            "Epoch 21/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.1754 - loss: 4.0954 - val_accuracy: 0.0631 - val_loss: 8.6353\n",
            "Epoch 22/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 67ms/step - accuracy: 0.1887 - loss: 4.0255 - val_accuracy: 0.0628 - val_loss: 8.7608\n",
            "Epoch 23/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 68ms/step - accuracy: 0.2028 - loss: 3.9108 - val_accuracy: 0.0602 - val_loss: 8.9155\n",
            "Epoch 24/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 68ms/step - accuracy: 0.2119 - loss: 3.8488 - val_accuracy: 0.0598 - val_loss: 9.0682\n",
            "Epoch 25/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 68ms/step - accuracy: 0.2326 - loss: 3.7395 - val_accuracy: 0.0596 - val_loss: 9.1827\n",
            "Epoch 26/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 68ms/step - accuracy: 0.2438 - loss: 3.6893 - val_accuracy: 0.0579 - val_loss: 9.2886\n",
            "Epoch 27/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 68ms/step - accuracy: 0.2561 - loss: 3.6147 - val_accuracy: 0.0575 - val_loss: 9.3964\n",
            "Epoch 28/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 70ms/step - accuracy: 0.2726 - loss: 3.5349 - val_accuracy: 0.0565 - val_loss: 9.5429\n",
            "Epoch 29/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 69ms/step - accuracy: 0.2776 - loss: 3.4663 - val_accuracy: 0.0561 - val_loss: 9.6344\n",
            "Epoch 30/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.2916 - loss: 3.3905 - val_accuracy: 0.0530 - val_loss: 9.7782\n",
            "Epoch 31/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.3048 - loss: 3.3183 - val_accuracy: 0.0591 - val_loss: 9.8838\n",
            "Epoch 32/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.3073 - loss: 3.2880 - val_accuracy: 0.0561 - val_loss: 9.9987\n",
            "Epoch 33/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.3273 - loss: 3.2073 - val_accuracy: 0.0565 - val_loss: 10.0753\n",
            "Epoch 34/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 68ms/step - accuracy: 0.3343 - loss: 3.1636 - val_accuracy: 0.0552 - val_loss: 10.1668\n",
            "Epoch 35/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.3402 - loss: 3.1117 - val_accuracy: 0.0540 - val_loss: 10.2761\n",
            "Epoch 36/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 72ms/step - accuracy: 0.3615 - loss: 3.0383 - val_accuracy: 0.0532 - val_loss: 10.3563\n",
            "Epoch 37/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.3676 - loss: 2.9887 - val_accuracy: 0.0546 - val_loss: 10.4721\n",
            "Epoch 38/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.3722 - loss: 2.9420 - val_accuracy: 0.0542 - val_loss: 10.5532\n",
            "Epoch 39/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 68ms/step - accuracy: 0.3803 - loss: 2.8972 - val_accuracy: 0.0536 - val_loss: 10.6308\n",
            "Epoch 40/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.3911 - loss: 2.8399 - val_accuracy: 0.0523 - val_loss: 10.7336\n",
            "Epoch 41/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.4009 - loss: 2.8058 - val_accuracy: 0.0552 - val_loss: 10.8130\n",
            "Epoch 42/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 68ms/step - accuracy: 0.4001 - loss: 2.7711 - val_accuracy: 0.0536 - val_loss: 10.9174\n",
            "Epoch 43/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 69ms/step - accuracy: 0.4106 - loss: 2.7353 - val_accuracy: 0.0548 - val_loss: 10.9500\n",
            "Epoch 44/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.4186 - loss: 2.6755 - val_accuracy: 0.0552 - val_loss: 11.0329\n",
            "Epoch 45/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 68ms/step - accuracy: 0.4207 - loss: 2.6622 - val_accuracy: 0.0542 - val_loss: 11.1197\n",
            "Epoch 46/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 72ms/step - accuracy: 0.4346 - loss: 2.5942 - val_accuracy: 0.0546 - val_loss: 11.1840\n",
            "Epoch 47/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 69ms/step - accuracy: 0.4456 - loss: 2.5682 - val_accuracy: 0.0527 - val_loss: 11.2525\n",
            "Epoch 48/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 68ms/step - accuracy: 0.4522 - loss: 2.5393 - val_accuracy: 0.0523 - val_loss: 11.3363\n",
            "Epoch 49/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 68ms/step - accuracy: 0.4552 - loss: 2.4940 - val_accuracy: 0.0542 - val_loss: 11.4001\n",
            "Epoch 50/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 68ms/step - accuracy: 0.4548 - loss: 2.4848 - val_accuracy: 0.0540 - val_loss: 11.4985\n",
            "Epoch 51/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 69ms/step - accuracy: 0.4666 - loss: 2.4338 - val_accuracy: 0.0525 - val_loss: 11.5418\n",
            "Epoch 52/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 72ms/step - accuracy: 0.4771 - loss: 2.3924 - val_accuracy: 0.0550 - val_loss: 11.6231\n",
            "Epoch 53/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.4735 - loss: 2.3828 - val_accuracy: 0.0511 - val_loss: 11.7116\n",
            "Epoch 54/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.4823 - loss: 2.3526 - val_accuracy: 0.0558 - val_loss: 11.7800\n",
            "Epoch 55/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 68ms/step - accuracy: 0.4829 - loss: 2.3284 - val_accuracy: 0.0558 - val_loss: 11.8040\n",
            "Epoch 56/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.5033 - loss: 2.2707 - val_accuracy: 0.0495 - val_loss: 11.8796\n",
            "Epoch 57/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 68ms/step - accuracy: 0.5053 - loss: 2.2531 - val_accuracy: 0.0538 - val_loss: 11.9614\n",
            "Epoch 58/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 68ms/step - accuracy: 0.5037 - loss: 2.2247 - val_accuracy: 0.0528 - val_loss: 12.0036\n",
            "Epoch 59/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 68ms/step - accuracy: 0.5108 - loss: 2.2081 - val_accuracy: 0.0546 - val_loss: 12.0958\n",
            "Epoch 60/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 69ms/step - accuracy: 0.5169 - loss: 2.1574 - val_accuracy: 0.0515 - val_loss: 12.1601\n",
            "Epoch 61/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 69ms/step - accuracy: 0.5294 - loss: 2.1396 - val_accuracy: 0.0519 - val_loss: 12.2056\n",
            "Epoch 62/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.5257 - loss: 2.1178 - val_accuracy: 0.0544 - val_loss: 12.2739\n",
            "Epoch 63/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 73ms/step - accuracy: 0.5409 - loss: 2.0714 - val_accuracy: 0.0534 - val_loss: 12.3336\n",
            "Epoch 64/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.5447 - loss: 2.0632 - val_accuracy: 0.0509 - val_loss: 12.4316\n",
            "Epoch 65/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.5507 - loss: 2.0332 - val_accuracy: 0.0536 - val_loss: 12.4438\n",
            "Epoch 66/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 70ms/step - accuracy: 0.5424 - loss: 2.0195 - val_accuracy: 0.0513 - val_loss: 12.5134\n",
            "Epoch 67/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.5540 - loss: 1.9875 - val_accuracy: 0.0527 - val_loss: 12.5574\n",
            "Epoch 68/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 69ms/step - accuracy: 0.5626 - loss: 1.9595 - val_accuracy: 0.0530 - val_loss: 12.6268\n",
            "Epoch 69/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 69ms/step - accuracy: 0.5678 - loss: 1.9556 - val_accuracy: 0.0538 - val_loss: 12.6992\n",
            "Epoch 70/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.5688 - loss: 1.9192 - val_accuracy: 0.0536 - val_loss: 12.7719\n",
            "Epoch 71/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.5736 - loss: 1.9024 - val_accuracy: 0.0534 - val_loss: 12.7657\n",
            "Epoch 72/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.5757 - loss: 1.8844 - val_accuracy: 0.0509 - val_loss: 12.8755\n",
            "Epoch 73/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.5758 - loss: 1.8801 - val_accuracy: 0.0511 - val_loss: 12.9075\n",
            "Epoch 74/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.5895 - loss: 1.8294 - val_accuracy: 0.0530 - val_loss: 12.9044\n",
            "Epoch 75/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 71ms/step - accuracy: 0.5932 - loss: 1.8070 - val_accuracy: 0.0527 - val_loss: 12.9791\n",
            "Epoch 76/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.5913 - loss: 1.8071 - val_accuracy: 0.0493 - val_loss: 13.0751\n",
            "Epoch 77/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.6009 - loss: 1.7782 - val_accuracy: 0.0538 - val_loss: 13.1289\n",
            "Epoch 78/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.6028 - loss: 1.7625 - val_accuracy: 0.0505 - val_loss: 13.1363\n",
            "Epoch 79/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 70ms/step - accuracy: 0.6120 - loss: 1.7331 - val_accuracy: 0.0486 - val_loss: 13.1831\n",
            "Epoch 80/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 74ms/step - accuracy: 0.6108 - loss: 1.7323 - val_accuracy: 0.0527 - val_loss: 13.2410\n",
            "Epoch 81/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.6140 - loss: 1.7060 - val_accuracy: 0.0530 - val_loss: 13.2912\n",
            "Epoch 82/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 69ms/step - accuracy: 0.6242 - loss: 1.6648 - val_accuracy: 0.0495 - val_loss: 13.3021\n",
            "Epoch 83/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 70ms/step - accuracy: 0.6220 - loss: 1.6579 - val_accuracy: 0.0534 - val_loss: 13.3689\n",
            "Epoch 84/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 71ms/step - accuracy: 0.6267 - loss: 1.6462 - val_accuracy: 0.0497 - val_loss: 13.4142\n",
            "Epoch 85/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.6280 - loss: 1.6375 - val_accuracy: 0.0493 - val_loss: 13.4885\n",
            "Epoch 86/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 70ms/step - accuracy: 0.6280 - loss: 1.6093 - val_accuracy: 0.0501 - val_loss: 13.5481\n",
            "Epoch 87/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 71ms/step - accuracy: 0.6314 - loss: 1.6094 - val_accuracy: 0.0499 - val_loss: 13.6090\n",
            "Epoch 88/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.6411 - loss: 1.5808 - val_accuracy: 0.0513 - val_loss: 13.6091\n",
            "Epoch 89/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.6394 - loss: 1.5750 - val_accuracy: 0.0513 - val_loss: 13.6854\n",
            "Epoch 90/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 69ms/step - accuracy: 0.6473 - loss: 1.5571 - val_accuracy: 0.0468 - val_loss: 13.7265\n",
            "Epoch 91/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 70ms/step - accuracy: 0.6496 - loss: 1.5350 - val_accuracy: 0.0499 - val_loss: 13.7643\n",
            "Epoch 92/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.6501 - loss: 1.5362 - val_accuracy: 0.0497 - val_loss: 13.8432\n",
            "Epoch 93/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.6487 - loss: 1.5314 - val_accuracy: 0.0511 - val_loss: 13.8538\n",
            "Epoch 94/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.6609 - loss: 1.5056 - val_accuracy: 0.0511 - val_loss: 13.8922\n",
            "Epoch 95/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.6651 - loss: 1.4790 - val_accuracy: 0.0486 - val_loss: 13.9025\n",
            "Epoch 96/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.6622 - loss: 1.4709 - val_accuracy: 0.0493 - val_loss: 13.9682\n",
            "Epoch 97/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 70ms/step - accuracy: 0.6651 - loss: 1.4508 - val_accuracy: 0.0484 - val_loss: 14.0396\n",
            "Epoch 98/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.6740 - loss: 1.4206 - val_accuracy: 0.0460 - val_loss: 14.0662\n",
            "Epoch 99/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 71ms/step - accuracy: 0.6715 - loss: 1.4297 - val_accuracy: 0.0495 - val_loss: 14.0789\n",
            "Epoch 100/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 70ms/step - accuracy: 0.6781 - loss: 1.3928 - val_accuracy: 0.0492 - val_loss: 14.1143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy: 0.6781 - loss: 1.3928 - val_accuracy: 0.0492 - val_loss: 14.1143"
      ],
      "metadata": {
        "id": "6dsnnd8ge9js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predicting The Next Word"
      ],
      "metadata": {
        "id": "3QZR_Xu3h_cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, tokenizer, text, max_sequence_len):\n",
        "  token_list = tokenizer.texts_to_sequences([text])[0]\n",
        "  if len(token_list) >= max_sequence_len:\n",
        "    token_list = token_list[-(max_sequence_len-1):]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  prediction = model.predict(token_list,verbose=0)\n",
        "  predicted_word_index = np.argmax(prediction,axis=1)[0]\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted_word_index:\n",
        "      return word\n",
        "  return None"
      ],
      "metadata": {
        "id": "35q4112Xf4b-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"to be or not to be\"\n",
        "max_sequence_len= model.input_shape[1]+1\n",
        "predicted_word = predict_next_word(model, tokenizer, input_text, max_sequence_len)\n",
        "print(f\"Input Text: {input_text}\")\n",
        "print(f\"Predicted Word: {predicted_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlVKK9Suguks",
        "outputId": "f75a7e44-9853-44ff-8a30-7efd769b83ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text: to be or not to be\n",
            "Predicted Word: buried\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving the Model"
      ],
      "metadata": {
        "id": "U8OSGSwJiHe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('next_word_lstm.h5')\n",
        "\n",
        "import pickle\n",
        "with open('tokenizer.pickle','wb') as handle:\n",
        "  pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHhPLkRZiFZK",
        "outputId": "b44a7aa1-468c-4ad0-e7a2-617f6f9d1966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install streamlit -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb5H8aEjqjjS",
        "outputId": "edb81ec9-d5ce-444a-8cec-e0aaff2678ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcVv9Shvq7t5",
        "outputId": "c13d9b24-53b8-4405-a79b-ff08b905ad81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.125.171.225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7MVo6S1rFZU",
        "outputId": "52a0b23f-0682-4fef-8a66-1039bc25dea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.171.225:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0Kyour url is: https://hip-oranges-think.loca.lt\n",
            "2024-12-11 17:50:00.703135: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-11 17:50:00.729557: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-11 17:50:00.737415: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-11 17:50:02.093113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0xe2b85b081f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0xe2b85b081f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0xe2b0cd26ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0xe2b0cd26ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "2024-12-11 17:55:00.800 Uncaught app execution\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 226, in build_wrapper\n",
            "    original_build_method(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\", line 186, in build\n",
            "    x = layer(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/name_scope.py\", line 61, in __exit__\n",
            "    name_scope_stack.pop()\n",
            "AttributeError: 'NoneType' object has no attribute 'pop'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 88, in exec_func_with_error_handling\n",
            "    result = func()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 579, in code_to_exec\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 8, in <module>\n",
            "    model = load_model('next_word_lstm.h5')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\", line 194, in load_model\n",
            "    return legacy_h5_format.load_model_from_hdf5(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\", line 133, in load_model_from_hdf5\n",
            "    model = saving_utils.model_from_config(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/legacy/saving/saving_utils.py\", line 85, in model_from_config\n",
            "    return serialization.deserialize_keras_object(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/legacy/saving/serialization.py\", line 495, in deserialize_keras_object\n",
            "    deserialized_obj = cls.from_config(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\", line 354, in from_config\n",
            "    model.add(layer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\", line 121, in add\n",
            "    self._maybe_rebuild()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\", line 140, in _maybe_rebuild\n",
            "    self.build(input_shape)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 224, in build_wrapper\n",
            "    with obj._open_name_scope():\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py\", line 649, in __exit__\n",
            "    super().__exit__(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/name_scope.py\", line 61, in __exit__\n",
            "    name_scope_stack.pop()\n",
            "AttributeError: 'NoneType' object has no attribute 'pop'\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}